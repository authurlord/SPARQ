{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "from utils.schedule_utils import load_data_split,table_to_str,table_to_str_sql,find_intersection_and_add_row_id,Prepare_Data_for_Operator_Sequence,format_document,batch_rerank_scores,ROLLBACK,merge_clean_and_format_df_dict,retrieve_rows_by_subtables,process_error_analysis_list\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from FlagEmbedding import FlagReranker\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Any\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.prompt_generate import build_wikitq_prompt_from_df,evaluate_predictions,filter_dataframe_from_responses,fix_sql_query,match_subtables,retrieve_rows_by_subtables,build_tab_fact_prompt_from_df\n",
    "from utils.async_llm import infer_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 读取必要文件（step 2）\n",
    "dataset_name = 'wikitq'\n",
    "split = 'test'\n",
    "tmp_save_path = 'datasets/schedule_test/wikitq'\n",
    "dataset = load_data_split(dataset_name,split)\n",
    "wikitq_df_processed = np.load(f'{tmp_save_path}/wikitq_df_processed.npy',allow_pickle=True).item()\n",
    "samples_short, samples_medium, samples_long = find_samples_by_length_from_dict(wikitq_df_processed,tokenizer_path='../../../models/Qwen3-4B-Instruct-2507/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2677/2677 [00:47<00:00, 55.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Samples: 2115; Total Samples: 2677\n",
      "Accuracy: 79.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1047/1047 [00:18<00:00, 56.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Samples: 783; Total Samples: 1047\n",
      "Accuracy: 74.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 620/620 [00:12<00:00, 50.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Samples: 429; Total Samples: 620\n",
      "Accuracy: 69.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wikitq_df = pd.read_csv('wikitq_test_result_4B.csv',index_col=0)\n",
    "for index_list in [samples_short, samples_medium, samples_long]:\n",
    "    acc_all, error_index_all, format_error_index_all = evaluate_predictions(dataset_name, wikitq_df.iloc[index_list], dataset)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'fetaqa'\n",
    "split = 'validation'\n",
    "dataset = load_data_split(dataset_name,split)\n",
    "tmp_save_path = 'datasets/schedule_test/tab_fact'\n",
    "Check_Model_Data_Sequence = np.load(f'{tmp_save_path}/Check_Model_Data_Sequence_wo_check.npy',allow_pickle=True).item()\n",
    "wikitq_df_processed = np.load(f'datasets/schedule_test/{dataset_name}/wikitq_df_processed.npy',allow_pickle=True).item()\n",
    "wikitq_df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'fetaqa'\n",
    "split = 'validation'\n",
    "dataset = load_data_split(dataset_name,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikitq_df_processed = np.load('datasets/schedule_test/fetaqa/wikitq_df_processed.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def find_long_samples(df_list: List[pd.DataFrame], \n",
    "                      tokenizer_path: str, \n",
    "                      threshold: int = 2000) -> List[Dict[str, Any]]:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "    def serialize(df: pd.DataFrame) -> str:\n",
    "        return \" \".join(\n",
    "            \" | \".join([f\"{col}: {val}\" for col, val in row.items()])\n",
    "            for _, row in df.iterrows()\n",
    "        )\n",
    "\n",
    "    results = []\n",
    "    for idx in range(len(df_list)):\n",
    "        df = df_list[idx]\n",
    "        text = serialize(df)\n",
    "        tokens = tokenizer(text, return_tensors=None)[\"input_ids\"]\n",
    "        token_len = len(tokens)\n",
    "        if token_len > threshold:\n",
    "            results.append(idx)\n",
    "    \n",
    "    return results\n",
    "\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def find_samples_by_length_from_dict(\n",
    "    df_dict: Dict[Any, pd.DataFrame], \n",
    "    tokenizer_path: str\n",
    ") -> Tuple[List[Any], List[Any], List[Any]]:\n",
    "    \"\"\"\n",
    "    Categorizes DataFrame keys from a dictionary into three lists based on \n",
    "    the serialized token length of each DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df_dict: A dictionary where keys are sample identifiers and values \n",
    "                 are pandas DataFrames.\n",
    "        tokenizer_path: The path to the Hugging Face tokenizer.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing three lists of dictionary keys:\n",
    "        - keys_short: Keys of samples with token length < 2000.\n",
    "        - keys_medium: Keys of samples with token length between 2000 and 4000.\n",
    "        - keys_long: Keys of samples with token length > 4000.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "    def serialize(df: pd.DataFrame) -> str:\n",
    "        \"\"\"Helper function to convert a DataFrame to a single string.\"\"\"\n",
    "        return \" \".join(\n",
    "            \" | \".join(f\"{col}: {val}\" for col, val in row.items())\n",
    "            for _, row in df.iterrows()\n",
    "        )\n",
    "\n",
    "    # Initialize lists to store the keys for each category\n",
    "    keys_short = []  # < 2000\n",
    "    keys_medium = [] # 2000 to 4000\n",
    "    keys_long = []   # > 4000\n",
    "\n",
    "    # Iterate over the dictionary's items (key-value pairs)\n",
    "    for key, df in df_dict.items():\n",
    "        text = serialize(df)\n",
    "        tokens = tokenizer.encode(text)\n",
    "        token_len = len(tokens)\n",
    "\n",
    "        # Categorize the key based on token length\n",
    "        if token_len > 2000:\n",
    "            keys_long.append(key)\n",
    "        elif token_len >= 1000:\n",
    "            keys_medium.append(key)\n",
    "        else:\n",
    "            keys_short.append(key)\n",
    "    \n",
    "    return keys_short, keys_medium, keys_long\n",
    "\n",
    "# long_index = find_long_samples(wikitq_df_processed,tokenizer_path='../../../models/Qwen3-4B-Instruct-2507/',threshold=2000)\n",
    "# samples_short, samples_medium, samples_long = find_samples_by_length_from_dict(wikitq_df_processed,tokenizer_path='../../../models/Qwen3-4B-Instruct-2507/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1627, 300, 76)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples_short), len(samples_medium), len(samples_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate training-free router result\n",
    "prompt_list = []\n",
    "for index in range(len(dataset)):\n",
    "    index = int(index)\n",
    "    prompt = build_wikitq_prompt_from_df(dataset,wikitq_df_processed[index],index,template_path='../prompts/training_free_router.txt',processed=True)\n",
    "    prompt_list.append(prompt)\n",
    "wikitq_df_rewrite_qa_semantic = wikitq_df\n",
    "wikitq_df_rewrite_qa_semantic['instruction'] = prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikitq_df_rewrite_qa_semantic.to_csv('../datasets/ablation/tab_fact_test_small_training_free_router.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'wikitq'\n",
    "split = 'test'\n",
    "dataset = load_data_split(dataset_name,split)\n",
    "tmp_save_path = 'datasets/schedule_test/wikitq'\n",
    "Check_Model_Data_Sequence = np.load(f'{tmp_save_path}/Check_Model_Data_Sequence_wo_check.npy',allow_pickle=True).item()\n",
    "wikitq_df_processed = np.load(f'datasets/schedule_test/{dataset_name}/wikitq_df_processed.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate training-free router result\n",
    "prompt_list = []\n",
    "for index in range():\n",
    "    index = int(index)\n",
    "    # rewritten_query = rewrite_query_list[index]\n",
    "    # sequence = Check_Model_Data_Sequence[index]['Sequence']\n",
    "    # insert_df = RAG_Hybrid[index]\n",
    "    prompt = build_wikitq_prompt_from_df(dataset,wikitq_df_processed[index],index,template_path='../prompts/training_free_router.txt',processed=True)\n",
    "    # prompt = prompt.replace(dataset[index]['question'], rewritten_query.split('SPECIFIC')[0][:-1])\n",
    "    # if sequence==[] or sequence.__contains__('Execute_SQL'):\n",
    "    # evidence = table_to_str_sql(processed_table['Execute_SQL'][index])\n",
    "    # prompt = prompt + evidence\n",
    "    prompt_list.append(prompt)\n",
    "wikitq_df_rewrite_qa_semantic = wikitq_df.iloc[long_index]\n",
    "wikitq_df_rewrite_qa_semantic['instruction'] = prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'tab_fact'\n",
    "split = 'test_small'\n",
    "dataset = load_data_split(dataset_name,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_LABELS = ['Base', 'Execute_SQL', 'RAG', 'Select_Column', 'Select_Row']\n",
    "def parse_valid_route(input):\n",
    "    try:\n",
    "        parse = eval(input)[0]\n",
    "        eval_parse = eval(parse)\n",
    "        result = [e for e in eval_parse if e in ALL_LABELS]\n",
    "    except:\n",
    "        result = []\n",
    "        for label in ALL_LABELS:\n",
    "            if input.lower().__contains__(label.lower()):\n",
    "                result.append(label)\n",
    "    ## 如果有非法字符\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 count number is 1301, 1 count number is 356, 2 count number is 297, 3 count number is 70\n"
     ]
    }
   ],
   "source": [
    "training_free_router = pd.read_csv('../datasets/ablation/tab_fact_test_small_training_free_router_output_4B.csv',index_col=0)\n",
    "training_free_router = [parse_valid_route(x) for x in training_free_router['predict'].tolist()]\n",
    "count = []\n",
    "for index in range(len(dataset)):\n",
    "    valid_seq = [s for s in training_free_router[index] if s!='Base']\n",
    "    count.append(len(valid_seq))\n",
    "# count / len(dataset)\n",
    "print(f'0 count number is {count.count(0)}, 1 count number is {count.count(1)}, 2 count number is {count.count(2)}, 3 count number is {count.count(3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = []\n",
    "for index in range(len(dataset)):\n",
    "    valid_seq = [s for s in Check_Model_Data_Sequence[index]['Sequence'] if s!='Base']\n",
    "    count.append(len(valid_seq))\n",
    "# count / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 count number is 1447, 1 count number is 440, 2 count number is 51, 3 count number is 86\n"
     ]
    }
   ],
   "source": [
    "print(f'0 count number is {count.count(0)}, 1 count number is {count.count(1)}, 2 count number is {count.count(2)}, 3 count number is {count.count(3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.50691699604744"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_select = 0\n",
    "count_all = 0\n",
    "for index in range(len(dataset)):\n",
    "    df = Check_Model_Data_Sequence[index]['data_entry']['table']\n",
    "    count_select += df.shape[0] * df.shape[1]\n",
    "    count_all += wikitq_df_processed[index].shape[0] * wikitq_df_processed[index].shape[1]\n",
    "count_select / len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "127.70027624309392 wikitq\n",
    "61.148480662983424 wikitq w/o Check\n",
    "82.05138339920948 Tab_Fact\n",
    "75.96 Tab_Fact w/o Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq_count_tab_fact\n",
    "0 count number is 1463, 1 count number is 447, 2 count number is 52, 3 count number is 62\n",
    "seql_count_tab_fact_wo_check\n",
    "0 count number is 1447, 1 count number is 440, 2 count number is 51, 3 count number is 86\n",
    "seq_count_wikitq\n",
    "0 count number is 716, 1 count number is 2948, 2 count number is 143, 3 count number is 537\n",
    "seq_count_wikitq_wo_check\n",
    "0 count number is 927, 1 count number is 2693, 2 count number is 119, 3 count number is 605"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.load('metrics_hyper_tau.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thres is 0.8, Acc is 75.23020257826887\n",
      "thres is 0.5, Acc is 75.1841620626151\n",
      "thres is 0.2, Acc is 74.37845303867404\n",
      "thres is 0.9, Acc is 58.057090239410684\n",
      "thres is 0.99, Acc is 51.58839779005525\n"
     ]
    }
   ],
   "source": [
    "for key in result.keys():\n",
    "    print(f\"thres is {key}, Acc is {result[key]['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Check_Model_Data = np.load('datasets/schedule_test/wikitq/Check_Model_Data_Ablation.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for tau 0.8, the average sequence length is 2.140193370165746\n",
      "for tau 0.5, the average sequence length is 2.2285911602209945\n",
      "for tau 0.2, the average sequence length is 2.2847605893186005\n",
      "for tau 0.9, the average sequence length is 2.0757366482504604\n",
      "for tau 0.99, the average sequence length is 1.8363259668508287\n"
     ]
    }
   ],
   "source": [
    "seq_length = {}\n",
    "for key in Check_Model_Data.keys():\n",
    "    count = 0\n",
    "    for index in Check_Model_Data[key].keys():\n",
    "        seq = Check_Model_Data[key][index]['Sequence']\n",
    "        seq_filter = [s for s in seq if s!='Base']\n",
    "        count += len(seq_filter)\n",
    "    seq_length[key] = count / len(Check_Model_Data[key].keys())\n",
    "    print(f'for tau {key}, the average sequence length is {seq_length[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num_metrics = {}\n",
    "for sample_num in [1,2,3,4,5]:\n",
    "    sample_num_metrics[sample_num] = {}\n",
    "sample_num_metrics[1]['acc'] = 3319 / 4344\n",
    "sample_num_metrics[2]['acc'] = 3362 / 4344\n",
    "sample_num_metrics[3]['acc'] = 3367 / 4344\n",
    "sample_num_metrics[4]['acc'] = 3376 / 4344\n",
    "sample_num_metrics[5]['acc'] = 3376 / 4344\n",
    "sample_num_metrics[1]['time'] = 9*60+41\n",
    "sample_num_metrics[2]['time'] = 9*60+52\n",
    "sample_num_metrics[3]['time'] = 10*60+7\n",
    "sample_num_metrics[4]['time'] = 10*60+23\n",
    "sample_num_metrics[5]['time'] = 10*60+22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'acc': 0.7640423572744015,\n",
       "  'time': 581,\n",
       "  'total_time': 0.31652854511970535},\n",
       " 2: {'acc': 0.7739410681399632,\n",
       "  'time': 592,\n",
       "  'total_time': 0.44129834254143646},\n",
       " 3: {'acc': 0.7750920810313076, 'time': 607, 'total_time': 0.5669889502762431},\n",
       " 4: {'acc': 0.7771639042357275, 'time': 623, 'total_time': 0.6929097605893186},\n",
       " 5: {'acc': 0.7771639042357275, 'time': 622, 'total_time': 0.8149171270718232}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_num_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num_metrics[1]['total_time'] = (263 + 531 + 581) / 4344\n",
    "sample_num_metrics[2]['total_time'] = (263 + 1062 + 592) / 4344\n",
    "sample_num_metrics[3]['total_time'] = (263 + 1593 + 607) / 4344\n",
    "sample_num_metrics[4]['total_time'] = (263 + 2124 + 623) / 4344\n",
    "sample_num_metrics[5]['total_time'] = (263 + 2655 + 622) / 4344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('sample_num_metrics.npy',sample_num_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hstar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
