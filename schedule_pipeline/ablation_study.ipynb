{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "## 这个notebook聚焦于 Ablation Study\n",
    "from utils.schedule_utils import load_data_split,table_to_str,table_to_str_sql,find_intersection_and_add_row_id,Prepare_Data_for_Operator_Sequence,format_document,batch_rerank_scores,ROLLBACK,merge_clean_and_format_df_dict,retrieve_rows_by_subtables,process_error_analysis_list\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from FlagEmbedding import FlagReranker\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Any\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.prompt_generate import build_wikitq_prompt_from_df,evaluate_predictions,filter_dataframe_from_responses,fix_sql_query,match_subtables,retrieve_rows_by_subtables,build_tab_fact_prompt_from_df\n",
    "from utils.async_llm import infer_prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ablation Study for Motivation Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RAG with HybridRetrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(dataset_name, df, dataset):\n",
    "    acc =0\n",
    "    error_index = []\n",
    "    format_error_index = []\n",
    "    # dataset_name = 'wikitq'\n",
    "    dataset_df_output = df\n",
    "    outputs = dataset_df_output.to_dict(orient='index')\n",
    "    # Iterate through each output and calculate the accuracy\n",
    "    count = 0\n",
    "    for i in tqdm(outputs.keys()):\n",
    "        count += 1\n",
    "        output = outputs[i]\n",
    "        pred_answer = None\n",
    "\n",
    "        # --- Prediction Parsing Logic ---\n",
    "        if dataset_name == 'wikitq':\n",
    "            try:\n",
    "                # Attempt to parse different possible output formats\n",
    "                raw_output = eval(output['predict'])[0]\n",
    "                if 'the answer is: ' in raw_output:\n",
    "                    pred_answer_all = raw_output.split('the answer is: ')[1]\n",
    "                elif 'Final Answer: ' in raw_output:\n",
    "                    pred_answer_all = raw_output.split('Final Answer: ')[1]\n",
    "                else:\n",
    "                    raise ValueError(\"Unrecognized format\")\n",
    "                \n",
    "                # Extract the answer, which is often quoted\n",
    "                pred_answer = pred_answer_all.split('\"')[1:2]\n",
    "\n",
    "            except Exception as e:\n",
    "                # If parsing fails, log it as a format error\n",
    "                # print(f'Format error in index {i}: {e}')\n",
    "                format_error_index.append(i)\n",
    "                pred_answer = [''] # Assign an empty prediction\n",
    "                pred_answer_all = ''\n",
    "                # print(pred_answer)\n",
    "\n",
    "        elif dataset_name == 'tab_fact':\n",
    "            # For TabFact, check for 'true' or 'false' (case-insensitive)\n",
    "            # if isinstance(output['predict'], str) and 'true' in output['predict'].lower():\n",
    "            try:\n",
    "                pred_answer_str = eval(output['predict'])[0].lower().split('statement is: ')[1].replace(\" \", \"\")\n",
    "            except:\n",
    "                pred_answer_str = eval(output['predict'])[0]\n",
    "            if 'false' in pred_answer_str:\n",
    "                pred_answer = [0]\n",
    "            else:\n",
    "                pred_answer = [1]\n",
    "\n",
    "            # gold_answer = result_df[str(i)]['ori_data_item']['answer_text']\n",
    "        gold_answer = dataset[i]['answer_text']\n",
    "        # Score is either 1 or 0\n",
    "        # print(pred_answer)\n",
    "        score = Evaluator().evaluate(\n",
    "        pred_answer,\n",
    "        gold_answer,\n",
    "        dataset=dataset_name,\n",
    "        question=output['question']\n",
    "        )\n",
    "        if dataset_name=='wikitq':\n",
    "            if score == False and isinstance(pred_answer_all, str):\n",
    "                score = Evaluator().evaluate(\n",
    "                    pred_answer_all.split(','),\n",
    "                    gold_answer,\n",
    "                    dataset=dataset_name,\n",
    "                    question=output.get('question', '') # Safely get question if available\n",
    "                )\n",
    "        acc += score\n",
    "        if score != 1:\n",
    "            error_index.append(i)\n",
    "            # if score!=1:\n",
    "            #     print(f'The prediction is {pred_answer}, while the ground truth is {gold_answer} for sample {i}.')\n",
    "        # except:\n",
    "        #     print(i)\n",
    "        #     pass\n",
    "    final_accuracy = 100 * acc / count if count > 0 else 0\n",
    "    print(f\"Correct Samples: {acc}; Total Samples: {count}\")\n",
    "    print(f\"Accuracy: {100*acc/count:.2f}\")\n",
    "    return final_accuracy, error_index, format_error_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 读取必要文件 （step 2）\n",
    "dataset_name = 'wikitq'\n",
    "split = 'validation'\n",
    "dataset = load_data_split(dataset_name,split)\n",
    "# wikitq_df_processed = np.load(f'datasets/schedule_test/{dataset_name}/wikitq_df_processed.npy',allow_pickle=True).item()\n",
    "wikitq_df_processed = np.load('/data/workspace/yanmy/HybridRAG/H-STAR/datasets/wikitq_df_validation.npy', allow_pickle=True).item()\n",
    "assert len(dataset) == len(wikitq_df_processed)\n",
    "wikitq_df = pd.DataFrame(dataset)\n",
    "long_index = np.load('../datasets/pipeline/valid_data_selection.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'tab_fact'\n",
    "split = 'test_small'\n",
    "dataset = load_data_split(dataset_name,split)\n",
    "wikitq_df_processed = np.load(f'datasets/schedule_test/{dataset_name}/wikitq_df_processed.npy',allow_pickle=True).item()\n",
    "# wikitq_df_processed = np.load('/data/workspace/yanmy/HybridRAG/H-STAR/datasets/wikitq_df_validation.npy', allow_pickle=True).item()\n",
    "assert len(dataset) == len(wikitq_df_processed)\n",
    "wikitq_df = pd.DataFrame(dataset)\n",
    "# long_index = np.load('../datasets/pipeline/valid_data_selection.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "for index in range(len(dataset)):\n",
    "    index = int(index)\n",
    "    prompt = build_wikitq_prompt_from_df(dataset,wikitq_df_processed[index],index,template_path='../prompts/rewrite_query.txt',processed=True)\n",
    "    prompt_list.append(prompt)\n",
    "# wikitq_df['instruction'] = prompt_list\n",
    "wikitq_df_rewrite = wikitq_df\n",
    "wikitq_df_rewrite['instruction'] = prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikitq_df_rewrite.to_csv('../datasets/ablation/tab_fact_test_small_rewrite.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_result_df = pd.read_csv('../datasets/ablation/tab_fact_test_small_rewrite_output_4B.csv',index_col=0)\n",
    "rewrite_result = {}\n",
    "# rewrite_result = [eval(item)[0] for item in rewrite_result['predict'].tolist()]\n",
    "for index in range(len(dataset)):\n",
    "    rewrite_result[index] = eval(rewrite_result_df.iloc[index,-1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('datasets/schedule_test/tab_fact/rewrite_query.npy',rewrite_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikitq_df_rewrite.to_csv('../datasets/ablation/wikitq_validation_rewrite.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_result = pd.read_csv('../datasets/ablation/wikitq_validation_rewrite_output_4B.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_query_list = {}\n",
    "for index in long_index:\n",
    "    index = int(index)\n",
    "    rewritten_query = eval(rewrite_result.loc[index,'predict'])[0]\n",
    "    # dataset[index]['question'] = rewritten_query\n",
    "    # rewrite_query_list.append(rewritten_query)\n",
    "    rewrite_query_list[index] = f\"[ORIGINAL]: {dataset[index]['question']}  \\n\" + rewritten_query\n",
    "    # wikitq_df.at[index,'rewritten_query'] = rewritten_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_Hybrid = np.load('../datasets/ablation/wikitq_valid_RAG_Hybrid.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_Semantic = np.load('../datasets/ablation/wikitq_valid_RAG_Hybrid_Semantic.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../datasets/ablation/wikitq_validation_rewrite_query_list_4B.npy',rewrite_query_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python Hybrid_Retrieve_Update_dict.py \\\n",
    "    --model_path /data/workspace/yanmy/models/bge-m3 \\\n",
    "    --dataset_name wikitq \\\n",
    "    --split validation \\\n",
    "    --index_path ../datasets/pipeline/valid_data_selection.npy \\\n",
    "    --output_path ../datasets/ablation/wikitq_valid_RAG_Hybrid.npy \\\n",
    "    --max_rows 50 \\\n",
    "    --max_cols 10 \\\n",
    "    --processed_df_path ../datasets/wikitq_df_validation.npy \\\n",
    "    --rewrite_query_path ../datasets/ablation/wikitq_validation_rewrite_query_list_4B.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python Hybrid_Retrieve_Update_dict.py \\\n",
    "    --model_path /data/workspace/yanmy/models/bge-m3 \\\n",
    "    --dataset_name tab_fact \\\n",
    "    --split test_small \\\n",
    "    --output_path ../datasets/ablation/tab_fact_test_small_RAG_Hybrid.npy \\\n",
    "    --max_rows 50 \\\n",
    "    --max_cols 10 \\\n",
    "    --processed_df_path datasets/schedule_test/tab_fact/wikitq_df_processed.npy \\\n",
    "    --rewrite_query_path datasets/schedule_test/tab_fact/rewrite_query.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python Hybrid_Retrieve_Semantic.py \\\n",
    "    --model_path /data/workspace/yanmy/models/bge-m3 \\\n",
    "    --dataset_name wikitq \\\n",
    "    --split validation \\\n",
    "    --index_path ../datasets/pipeline/valid_data_selection.npy \\\n",
    "    --output_path ../datasets/ablation/wikitq_valid_RAG_Hybrid_Semantic.npy \\\n",
    "    --max_rows 50 \\\n",
    "    --max_cols 10 \\\n",
    "    --processed_df_path ../datasets/wikitq_df_validation.npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1640787/1094960381.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wikitq_df_qa['instruction'] = prompt_list\n"
     ]
    }
   ],
   "source": [
    "prompt_list = []\n",
    "for index in long_index:\n",
    "    index = int(index)\n",
    "    # rewritten_query = rewrite_query_list[index]\n",
    "    # sequence = Check_Model_Data_Sequence[index]['Sequence']\n",
    "    # insert_df = RAG_Hybrid[index]\n",
    "    prompt = build_wikitq_prompt_from_df(dataset,wikitq_df_processed[index],index,template_path='../prompts/generic_reasoning/chain_of_thought_wtq.txt',processed=True)\n",
    "    # prompt = prompt.replace(dataset[index]['question'], rewritten_query.split('SPECIFIC')[0][:-1])\n",
    "    # if sequence==[] or sequence.__contains__('Execute_SQL'):\n",
    "    # evidence = table_to_str_sql(processed_table['Execute_SQL'][index])\n",
    "    # prompt = prompt + evidence\n",
    "    prompt_list.append(prompt)\n",
    "wikitq_df_qa = wikitq_df.iloc[long_index]\n",
    "wikitq_df_qa['instruction'] = prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1640787/2915256273.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wikitq_df_rewrite_qa_semantic['instruction'] = prompt_list\n"
     ]
    }
   ],
   "source": [
    "prompt_list = []\n",
    "for index in long_index:\n",
    "    index = int(index)\n",
    "    rewritten_query = rewrite_query_list[index]\n",
    "    # sequence = Check_Model_Data_Sequence[index]['Sequence']\n",
    "    insert_df = RAG_Hybrid[index]\n",
    "    prompt = build_wikitq_prompt_from_df(dataset,RAG_Semantic[index],index,template_path='../prompts/generic_reasoning/chain_of_thought_wtq.txt',processed=True)\n",
    "    # prompt = prompt.replace(dataset[index]['question'], rewritten_query.split('SPECIFIC')[0][:-1])\n",
    "    # if sequence==[] or sequence.__contains__('Execute_SQL'):\n",
    "    # evidence = table_to_str_sql(processed_table['Execute_SQL'][index])\n",
    "    # prompt = prompt + evidence\n",
    "    prompt_list.append(prompt)\n",
    "wikitq_df_rewrite_qa_semantic = wikitq_df.iloc[long_index]\n",
    "wikitq_df_rewrite_qa_semantic['instruction'] = prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikitq_df_rewrite_qa_semantic.to_csv('../datasets/ablation/wikitq_validation_qa_semantic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1640787/1816279342.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wikitq_df_rewrite_qa['instruction'] = prompt_list\n"
     ]
    }
   ],
   "source": [
    "prompt_list = []\n",
    "for index in long_index:\n",
    "    index = int(index)\n",
    "    rewritten_query = rewrite_query_list[index]\n",
    "    # sequence = Check_Model_Data_Sequence[index]['Sequence']\n",
    "    insert_df = RAG_Hybrid[index]\n",
    "    prompt = build_wikitq_prompt_from_df(dataset,RAG_Hybrid[index],index,template_path='../prompts/text_reason_wtq.txt',processed=True)\n",
    "    # prompt = prompt.replace(dataset[index]['question'], rewritten_query.split('SPECIFIC')[0][:-1])\n",
    "    # if sequence==[] or sequence.__contains__('Execute_SQL'):\n",
    "    # evidence = table_to_str_sql(processed_table['Execute_SQL'][index])\n",
    "    # prompt = prompt + evidence\n",
    "    prompt_list.append(prompt + sql_execute_result.iloc[index,-2].split('<output>')[-1])\n",
    "wikitq_df_rewrite_qa = wikitq_df.iloc[long_index]\n",
    "wikitq_df_rewrite_qa['instruction'] = prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikitq_df_qa.to_csv('../datasets/ablation/wikitq_validation_qa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikitq_df_rewrite_qa.to_csv('../datasets/ablation/wikitq_validation_RAG_Hybrid_noSpecific_qa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_execute_result = pd.read_csv('../datasets/pipeline/wikitq_valid_sql_exec_qa_output_4B.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/476 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:14<00:00, 31.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Samples: 237; Total Samples: 476\n",
      "Accuracy: 49.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# wikitq_df_rewrite_qa_output = pd.read_csv('../datasets/ablation/wikitq_validation_RAG_Hybrid_noRewrite_qa_output_4B.csv',index_col=0)\n",
    "# wikitq_df_rewrite_qa_output = pd.read_csv('../datasets/ablation/wikitq_validation_RAG_Hybrid_noSpecific_qa_output_4B.csv',index_col=0)\n",
    "# wikitq_df_rewrite_qa_output = pd.read_csv('../datasets/ablation/wikitq_validation_qa_output_4B.csv',index_col=0)\n",
    "# wikitq_df_rewrite_qa_output = pd.read_csv('../datasets/ablation/wikitq_validation_qa_semantic_output_4B.csv',index_col=0)\n",
    "wikitq_df_rewrite_qa_output = pd.read_csv('../datasets/ablation/wikitq_valid_training_free_qa_output_4B.csv',index_col=0)\n",
    "final_accuracy, error_index, format_error_index = evaluate_predictions('wikitq', wikitq_df_rewrite_qa_output, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_table_valid_row = np.load('../datasets/pipeline/filtered_tables_row.npy',allow_pickle=True).item()\n",
    "filtered_table_valid_col = np.load('../datasets/pipeline/filtered_tables_col.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2647058823529411 row parse fail, 0.025210084033613467 col parse fail, 0.21638655462184875 sql contain additional evidence\n"
     ]
    }
   ],
   "source": [
    "row_success_count = 0\n",
    "col_success_count = 0\n",
    "sql_success_count = 0\n",
    "# len(filtered_table_valid_row),len(filtered_table_valid_col)\n",
    "for index in long_index:\n",
    "    index = int(index)\n",
    "    if len(filtered_table_valid_row[index]) < len(wikitq_df_processed[index]):\n",
    "        row_success_count += 1\n",
    "    if filtered_table_valid_col[index].shape[1] < wikitq_df_processed[index].shape[1]:\n",
    "        col_success_count += 1\n",
    "    sql_input = sql_execute_result.iloc[index,-2].split('<output>')[-1] ## template+table+qustion 的末尾\n",
    "    if sql_input.__contains__('additional evidence'):\n",
    "        sql_success_count += 1\n",
    "print(f'{1 - row_success_count/len(long_index)} row parse fail, {1 - col_success_count/len(long_index)} col parse fail, {1 - sql_success_count/len(long_index)} sql contain additional evidence')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SQL success parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_sql = 0\n",
    "all_sql  = 0\n",
    "processed_table = np.load('datasets/schedule_test/wikitq/processed_table.npy',allow_pickle=True).item()\n",
    "filtered_table_test_row = processed_table['Select_Row']\n",
    "filtered_table_test_col = processed_table['Select_Column']\n",
    "wikitq_df_processed = np.load('datasets/schedule_test/wikitq/wikitq_df_processed.npy',allow_pickle=True).item()\n",
    "sql_execute_result = processed_table['Execute_SQL']\n",
    "for key in filtered_table_test_row.keys():\n",
    "    all_sql += 1\n",
    "    if len(filtered_table_test_row[key]) < len(wikitq_df_processed[key]):\n",
    "        success_sql += 1\n",
    "for key in filtered_table_test_col.keys():\n",
    "    all_sql += 1\n",
    "    if filtered_table_test_col[key].shape[1] < wikitq_df_processed[key].shape[1]:\n",
    "        success_sql += 1\n",
    "for key in sql_execute_result.keys():\n",
    "    all_sql += 1\n",
    "    if len(sql_execute_result[key])>0:\n",
    "        success_sql += 1\n",
    "# sql_execute_result = np.load('')\n",
    "# assert len(filtered_table_test_row) == len(filtered_table_test_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777998017839445"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_sql / all_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:09<00:00, 50.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Samples: 282; Total Samples: 476\n",
      "Accuracy: 59.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wikitq_df_rewrite_qa_output = pd.read_csv('../datasets/pipeline/wikitq_valid_row_sql_qa_output_4B.csv',index_col=0).iloc[long_index]\n",
    "wikitq_df_rewrite_qa_output = pd.read_csv('../datasets/pipeline/wikitq_valid_col_sql_qa_output_4B.csv',index_col=0).iloc[long_index]\n",
    "final_accuracy, error_index, format_error_index = evaluate_predictions('wikitq', wikitq_df_rewrite_qa_output, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/pipeline/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Free Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/workspace/yanmy/HybridRAG/H-STAR/router/test_data_retrieved.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1640787/1807860779.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wikitq_df_rewrite_qa_semantic['instruction'] = prompt_list\n"
     ]
    }
   ],
   "source": [
    "## generate training-free router result\n",
    "prompt_list = []\n",
    "for index in long_index:\n",
    "    index = int(index)\n",
    "    # rewritten_query = rewrite_query_list[index]\n",
    "    # sequence = Check_Model_Data_Sequence[index]['Sequence']\n",
    "    # insert_df = RAG_Hybrid[index]\n",
    "    prompt = build_wikitq_prompt_from_df(dataset,wikitq_df_processed[index],index,template_path='../prompts/training_free_router.txt',processed=True)\n",
    "    # prompt = prompt.replace(dataset[index]['question'], rewritten_query.split('SPECIFIC')[0][:-1])\n",
    "    # if sequence==[] or sequence.__contains__('Execute_SQL'):\n",
    "    # evidence = table_to_str_sql(processed_table['Execute_SQL'][index])\n",
    "    # prompt = prompt + evidence\n",
    "    prompt_list.append(prompt)\n",
    "wikitq_df_rewrite_qa_semantic = wikitq_df.iloc[long_index]\n",
    "wikitq_df_rewrite_qa_semantic['instruction'] = prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikitq_df_rewrite_qa_semantic.to_csv('../datasets/ablation/wikitq_valid_training_free_router.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tree_result = pd.read_csv('../datasets/ablation/wikitq_valid_training_free_router_output_4B.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1640787/4259182048.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wikitq_df_training_free_qa['instruction'] = prompt_list\n"
     ]
    }
   ],
   "source": [
    "# eval(training_tree_result.iloc[221,-1])[0]\n",
    "def parse_valid_route(input):\n",
    "    parse = eval(input)[0]\n",
    "    return eval(parse)\n",
    "prompt_list = []\n",
    "count = 0\n",
    "count_prun = 0\n",
    "count_original = 0\n",
    "count_seq_len = 0\n",
    "for index in long_index:\n",
    "    index = int(index)\n",
    "    route = parse_valid_route(training_tree_result.loc[index,'predict'])\n",
    "    # count_seq_len += len(route)\n",
    "\n",
    "    # if 'Select_Column' in route and 'Select_Row' in route:\n",
    "    #     df_row = filtered_table_valid_row[index]\n",
    "    #     df_col = filtered_table_valid_col[index]\n",
    "    #     df_final = find_intersection_and_add_row_id(df_row,df_col)\n",
    "    #     count += 4\n",
    "    # elif 'Select_Column' in route:\n",
    "    #     df_final = filtered_table_valid_col[index]\n",
    "    #     count += 2\n",
    "    # elif 'Select_Row' in route:\n",
    "    #     df_final = filtered_table_valid_row[index]\n",
    "    #     count += 2\n",
    "    # else:\n",
    "    #     df_final = wikitq_df_processed[index]\n",
    "    # if 'RAG' in route:\n",
    "    #     df_final = find_intersection_and_add_row_id(df_final,RAG_Hybrid[index])\n",
    "    if 'Select_Row' in route:\n",
    "        df_final = filtered_table_valid_row[index]\n",
    "        count += 2\n",
    "        count_seq_len += 1\n",
    "    else:\n",
    "        df_final = wikitq_df_processed[index]\n",
    "    prompt = build_wikitq_prompt_from_df(dataset,df_final,index,template_path='../prompts/text_reason_wtq.txt',processed=True)\n",
    "    count_prun += df_final.shape[0] * df_final.shape[1]\n",
    "    count_original += wikitq_df_processed[index].shape[0] * wikitq_df_processed[index].shape[1]\n",
    "    if 'Execute_SQL' in route:\n",
    "        sql_input = sql_execute_result.iloc[index,-2].split('<output>')[-1]\n",
    "        prompt = prompt + sql_input\n",
    "        count += 3\n",
    "        count_seq_len += 1\n",
    "    prompt_list.append(prompt)\n",
    "wikitq_df_training_free_qa = wikitq_df.iloc[long_index]\n",
    "wikitq_df_training_free_qa['instruction'] = prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "602"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.7330156694619411 router 994 Full Route\n",
    "0.5642 router + check 602"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.260504201680672"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count / len(long_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikitq_df_training_free_qa.to_csv('../datasets/ablation/wikitq_valid_training_free_qa_route.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/476 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:09<00:00, 52.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Samples: 304; Total Samples: 476\n",
      "Accuracy: 63.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# wikitq_df_rewrite_qa_output = pd.read_csv('../datasets/ablation/wikitq_valid_training_free_qa_output_4B.csv',index_col=0)\n",
    "wikitq_df_rewrite_qa_output = pd.read_csv('../datasets/ablation/wikitq_valid_training_free_qa_route_output_4B.csv',index_col=0)\n",
    "final_accuracy, error_index, format_error_index = evaluate_predictions('wikitq', wikitq_df_rewrite_qa_output, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average row number is 78.73529411764706, average col number is 7.571428571428571,maximum row is 753, maximum col is 21\n"
     ]
    }
   ],
   "source": [
    "row_num = []\n",
    "col_num = []\n",
    "for index in long_index:\n",
    "    index = int(index)\n",
    "    row_num.append(wikitq_df_processed[index].shape[0])\n",
    "    col_num.append(wikitq_df_processed[index].shape[1])\n",
    "print(f'average row number is {np.mean(row_num)}, average col number is {np.mean(col_num)},maximum row is {np.max(row_num)}, maximum col is {np.max(col_num)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hstar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
