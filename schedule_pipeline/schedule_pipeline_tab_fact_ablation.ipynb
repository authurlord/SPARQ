{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "from utils.schedule_utils import load_data_split,table_to_str,table_to_str_sql,find_intersection_and_add_row_id,Prepare_Data_for_Operator_Sequence,format_document,batch_rerank_scores,ROLLBACK,merge_clean_and_format_df_dict,retrieve_rows_by_subtables,process_error_analysis_list\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from FlagEmbedding import FlagReranker\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Any\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.prompt_generate import build_wikitq_prompt_from_df,evaluate_predictions,filter_dataframe_from_responses,fix_sql_query,match_subtables,retrieve_rows_by_subtables,build_tab_fact_prompt_from_df\n",
    "from utils.async_llm import infer_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_LABELS = ['Base', 'Execute_SQL', 'RAG', 'Select_Column', 'Select_Row']\n",
    "def parse_valid_route(input):\n",
    "    try:\n",
    "        parse = eval(input)[0]\n",
    "        eval_parse = eval(parse)\n",
    "        result = [e for e in eval_parse if e in ALL_LABELS]\n",
    "    except:\n",
    "        result = []\n",
    "        for label in ALL_LABELS:\n",
    "            if input.lower().__contains__(label.lower()):\n",
    "                result.append(label)\n",
    "    ## 如果有非法字符\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"VLLM_ATTENTION_BACKEND\"] = \"FLASHINFER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-20 19:30:47 [__init__.py:216] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import argparse\n",
    "from vllm.lora.request import LoRARequest\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 参数记录 for tab_fact\n",
    "N_PARALLEL = 32 ## only for convert_df_type_parallel.py of data preprocess，一次性离线的\n",
    "embedding_base_model_path = '/data/workspace/yanmy/models/bge-m3'\n",
    "router_model_path = '/data/workspace/yanmy/HybridRAG/H-STAR/router/bge-m3-router-tab_fact-hn' ## fine-tuned router model path\n",
    "check_moedl_path = '/data/workspace/yanmy/HybridRAG/H-STAR/check/output/bge-reranker-v2-m3-finetuned-tab_fact' ## check model path\n",
    "tmp_save_path = 'datasets/schedule_test/tab_fact' ## 临时存储路径\n",
    "dataset_name = 'tab_fact'\n",
    "split = 'test_small'\n",
    "tau = 0.75\n",
    "check_tau = 0.8\n",
    "ALL_LABELS = [\n",
    "    'Base', 'Select_Row', 'Select_Column', 'Execute_SQL', 'RAG_20_5', \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_20_5 = np.load('../datasets/ablation/tab_fact_test_small_RAG_Hybrid.npy',allow_pickle=True).item()\n",
    "wikitq_df_processed = np.load('datasets/schedule_test/tab_fact/wikitq_df_processed.npy',allow_pickle=True).item()\n",
    "rewrite_query_list = np.load('datasets/schedule_test/tab_fact/rewrite_query.npy',allow_pickle=True)\n",
    "training_free_router = pd.read_csv('../datasets/ablation/tab_fact_test_small_training_free_router_output_4B.csv',index_col=0)\n",
    "training_free_router = [parse_valid_route(x) for x in training_free_router['predict'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_table = np.load('../datasets/check/tab_fact_test_small_processed_table.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 读取必要文件 （step 2）\n",
    "dataset = load_data_split(dataset_name,split)\n",
    "wikitq_df_processed = np.load('datasets/schedule_test/tab_fact/wikitq_df_processed.npy',allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 5\n",
    "# with open(f'{tmp_save_path}/inference_result.pkl', 'rb') as f:\n",
    "#     error_analysis_row = pickle.load(f)\n",
    "# ranked_result = process_error_analysis_list(error_analysis_row, truncate=True, tau=tau)\n",
    "ranked_result = process_error_analysis_list(training_free_router, truncate=True, tau=tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run Check Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_Data_for_Operator_Sequence(index,sequence,dataset, processed_table, remove_operator = []):\n",
    "    data_entry = {\n",
    "    'id': dataset[index]['id'],\n",
    "    'query': dataset[index]['question'], ## 没有ReWrite，暂时不做变化\n",
    "    # 'table': wikitq_df_processed[index],\n",
    "    'title': dataset[index]['table']['page_title'], ## 不变\n",
    "    # 'SQL': sql_command['sql'] + table_to_str(sql_command['table']) ,\n",
    "        }\n",
    "    sequence = [s for s in sequence if s not in remove_operator]\n",
    "    if sequence.__contains__('Execute_SQL'): ## 有Execute_SQL计算符\n",
    "        sql_list = [sql_count for sql_count in processed_table['Execute_SQL_count'] if sql_count['id']==index]\n",
    "        # sql_command = sql_list[0]\n",
    "        if len(sql_list)==0:\n",
    "            SQL = ''\n",
    "        else:\n",
    "            sql_command = sql_list[0]\n",
    "            SQL = sql_command['sql'] + table_to_str(sql_command['table'])\n",
    "        data_entry['SQL'] = SQL\n",
    "    else:\n",
    "        data_entry['SQL'] = ''\n",
    "    extraction_sequence = [s for s in sequence if s!='Execute_SQL']\n",
    "    # print(extraction_sequence)\n",
    "    if len(extraction_sequence)==1: ## Only One Operator\n",
    "        method = extraction_sequence[0]\n",
    "        data_entry['table'] = processed_table[method][index]\n",
    "    elif len(extraction_sequence)==2:\n",
    "        table_1 = processed_table[extraction_sequence[0]][index]\n",
    "        table_2 = processed_table[extraction_sequence[1]][index]\n",
    "        # print(table_1.shape, table_2.shape)\n",
    "        table_intersection = find_intersection_and_add_row_id(table_1,table_2)\n",
    "        data_entry['table'] = table_intersection\n",
    "    elif len(extraction_sequence)==3:\n",
    "        table_1 = processed_table[extraction_sequence[0]][index]\n",
    "        table_2 = processed_table[extraction_sequence[1]][index]\n",
    "        table_3 = processed_table[extraction_sequence[2]][index]\n",
    "        # print(table_1.shape, table_2.shape)\n",
    "        table_intersection = find_intersection_and_add_row_id(table_1,table_2)\n",
    "        table_intersection = find_intersection_and_add_row_id(table_intersection,table_3)\n",
    "        data_entry['table'] = table_intersection\n",
    "    elif len(extraction_sequence)==0:\n",
    "        data_entry['table'] = processed_table['Base'][index]\n",
    "    assert data_entry.__contains__('SQL')\n",
    "    assert data_entry.__contains__('table')\n",
    "    return data_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对每一条数据，维护一个 Sequence_Operator\n",
    "# 每条数据应该对应一个 Dict,这个Dict 包含了3 个参数：\n",
    "    # id: index\n",
    "    # Sequence: Operator Sequence\n",
    "    # Terminated: True/False\n",
    "    # Check Score: CrossEncoder 分数\n",
    "    # Check Status: True/False,当前是否被计算\n",
    "# 对每条数据，如果 Terminated = True，则不参与计算\n",
    "# 对应的，如果 Terminated = False，那么查看 Check Status,如果 Statue=False，那么计算 Check_Score\n",
    "# 每一轮计算之后，Check_Score 更新，Check Statue更新，该轮开始判定，用一个 threshold\n",
    "# 如果 Check Status = True, Check Score >= Threshold，那么标注 Terminated = True，当前路径被接收\n",
    "# 如果 Check Status = True, Check Score < Threshold，那么Terminated = False, Check Status = False, Check Score 清空\n",
    "# Check Score 触发 RollBack 机制，即除了‘Execute_SQL'外，Extract 回退，重新计算当前流程\n",
    "# 如果当前操作符只有'Execute_SQL’和空（所有 RollBack 均未被接收），那么触发 FORWARD,Terminated  = True，强制修改 Operator Sequence 为['Execute_SQL']\n",
    "Check_Model_Data_Sequence = {}\n",
    "for key in ranked_result.keys(): ## 遍历所有数据,初始化\n",
    "    start_sequence = ranked_result[key]\n",
    "    Check_Model_Data_Sequence[key] = {}\n",
    "    Check_Model_Data_Sequence[key]['id'] = key\n",
    "    Check_Model_Data_Sequence[key]['Sequence'] = start_sequence\n",
    "    if start_sequence == ['Base'] or start_sequence == ['Execute_SQL']: ## Terminated 不参与计算\n",
    "        Check_Model_Data_Sequence[key]['Terminated'] = True\n",
    "        Check_Model_Data_Sequence[key]['Check_Status'] = False\n",
    "        Check_Model_Data_Sequence[key]['Check_Score'] = 0.0\n",
    "    else:\n",
    "        Check_Model_Data_Sequence[key]['Terminated'] = False\n",
    "        Check_Model_Data_Sequence[key]['Check_Status'] = False\n",
    "        Check_Model_Data_Sequence[key]['Check_Score'] = 0.0\n",
    "# Check_Model_Data_Sequence[4]\n",
    "for key in Check_Model_Data_Sequence.keys():\n",
    "    data_entry = Prepare_Data_for_Operator_Sequence(key,Check_Model_Data_Sequence[key]['Sequence'],dataset, processed_table)\n",
    "    Check_Model_Data_Sequence[key]['data_entry'] = data_entry\n",
    "## Check\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load ReRanking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker_model = FlagReranker(check_moedl_path, use_fp16=True, devices='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering items to rerank (Terminated=False and data_entry exists)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:   0%|          | 0/2024 [8:12:46<?, ?it/s]\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2025' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2024' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2023' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2022' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2021' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2020' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2019' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2018' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2017' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2016' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2015' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2014' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2013' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2012' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2011' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2010' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2009' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2008' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2007' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2006' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2005' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2004' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2003' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2002' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2001' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2000' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1999' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1998' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1997' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1996' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1995' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1994' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1993' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1992' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1991' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1990' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1989' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1988' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1987' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1986' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1985' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1984' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1983' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1982' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1981' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1980' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1979' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1978' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1977' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1976' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1975' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1974' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1973' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1972' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1971' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1970' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1969' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1968' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1967' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1966' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1965' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1964' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1963' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1962' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1961' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1960' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1959' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1958' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1957' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1956' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1955' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1954' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1953' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1952' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1951' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1950' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1949' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1948' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1947' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1946' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1945' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1944' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1943' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1942' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1941' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1940' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1939' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1938' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1937' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1936' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1935' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1934' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1933' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1932' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1931' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1930' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1929' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1928' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1927' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1926' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1925' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1924' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1923' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1922' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1921' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1920' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1919' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1918' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1917' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1916' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1915' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1914' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1913' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1912' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1911' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1910' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1909' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1908' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1907' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1906' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1905' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1904' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1903' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1902' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1901' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1900' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1899' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1898' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1897' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1896' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1895' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1894' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1893' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1892' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1891' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1890' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1889' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1888' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1887' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1886' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1885' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1884' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1883' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1882' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1881' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1880' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1879' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1878' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1877' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1876' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1875' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1874' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1873' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1872' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1871' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1870' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1869' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1868' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1867' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1866' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1865' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1864' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1863' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1862' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1861' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1860' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1859' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1858' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1857' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1856' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1855' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1854' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1853' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1852' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1851' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1850' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1849' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1848' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1847' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1846' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1845' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1844' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1843' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1842' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1841' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1840' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1839' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1838' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1837' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1836' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1835' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1834' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1833' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1832' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1831' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1830' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1829' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1828' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1827' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1826' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1825' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1824' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1823' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1822' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1821' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1820' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1819' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1818' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1817' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1816' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1815' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1814' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1813' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1812' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1811' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1810' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1809' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1808' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1807' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1806' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1805' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1804' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1803' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1802' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1801' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1800' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1799' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1798' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1797' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1796' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1795' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1794' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1793' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1792' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1791' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1790' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1789' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1788' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1787' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1786' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1785' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1784' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1783' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1782' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1781' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1780' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1779' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1778' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1777' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1776' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1775' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1774' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1773' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1772' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1771' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1770' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1769' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1768' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1767' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1766' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1765' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1764' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1763' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1762' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1761' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1760' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1759' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1758' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1757' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1756' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1755' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1754' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1753' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1752' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1751' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1750' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1749' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1748' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1747' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1746' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1745' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1744' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1743' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1742' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1741' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1740' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1739' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1738' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1737' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1736' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1735' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1734' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1733' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1732' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1731' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1730' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1729' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1728' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1727' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1726' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1725' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1724' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1723' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1722' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1721' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1720' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1719' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1718' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1717' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1716' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1715' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1714' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1713' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1712' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1711' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1710' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1709' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1708' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1707' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1706' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1705' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1704' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1703' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1702' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1701' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1700' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1699' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1698' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1697' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1696' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1695' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1694' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1693' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1692' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1691' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1690' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1689' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1688' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1687' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1686' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1685' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1684' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1683' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1682' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1681' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1680' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1679' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1678' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1677' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1676' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1675' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1674' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1673' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1672' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1671' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1670' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1669' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1668' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1667' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1666' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1665' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1664' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1663' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1662' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1661' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1660' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1659' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1658' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1657' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1656' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1655' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1654' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1653' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1652' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1651' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1650' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1649' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1648' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1647' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1646' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1645' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1644' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1643' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1642' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1641' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1640' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1639' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1638' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1637' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1636' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1635' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1634' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1633' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1632' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1631' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1630' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1629' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1628' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1627' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1626' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1625' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1624' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1623' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1622' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1621' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1620' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1619' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1618' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1617' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1616' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1615' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1614' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1613' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1612' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1611' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1610' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1609' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1608' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1607' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1606' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1605' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1604' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1603' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1602' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1601' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1600' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1599' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1598' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1597' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1596' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1595' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1594' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1593' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1592' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1591' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1590' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1589' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1588' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1587' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1586' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1585' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1584' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1583' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1582' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1581' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1580' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1579' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1578' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1577' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1576' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1575' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1574' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1573' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1572' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1571' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1570' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1569' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1568' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1567' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1566' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1565' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1564' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1563' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1562' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1561' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1560' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1559' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1558' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1557' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1556' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1555' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1554' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1553' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1552' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1551' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1550' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1549' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1548' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1547' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1546' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1545' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1544' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1543' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1542' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1541' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1540' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1539' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1538' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1537' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1536' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1535' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1534' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1533' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1532' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1531' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1530' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1529' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1528' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1527' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1526' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1525' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1524' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1523' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1522' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1521' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1520' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1519' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1518' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1517' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1516' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1515' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1514' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1513' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1512' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1511' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1510' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1509' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1508' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1507' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1506' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1505' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1504' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1503' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1502' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1501' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1500' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1499' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1498' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1497' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1496' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1495' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1494' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1493' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1492' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1491' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1490' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1489' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1488' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1487' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1486' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1485' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1484' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1483' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1482' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1481' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1480' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1479' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1478' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1477' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1476' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1475' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1474' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1473' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1472' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1471' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1470' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1469' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1468' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1467' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1466' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1465' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1464' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1463' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1462' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1461' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1460' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1459' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1458' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1457' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1456' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1455' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1454' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1453' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1452' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1451' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1450' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1449' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1448' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1447' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1446' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1445' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1444' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1443' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1442' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1441' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1440' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1439' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1438' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1437' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1436' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1435' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1434' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1433' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1432' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1431' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1430' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1429' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1428' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1427' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1426' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1425' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1424' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1423' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1422' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1421' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1420' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1419' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1418' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1417' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1416' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1415' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1414' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1413' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1412' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1411' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1410' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1409' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1408' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1407' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1406' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1405' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1404' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1403' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1402' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1401' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1400' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1399' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1398' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1397' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1396' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1395' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1394' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1393' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1392' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1391' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1390' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1389' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1388' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1387' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1386' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1385' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1384' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1383' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1382' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1381' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1380' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1379' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1378' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1377' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1376' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1375' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1374' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1373' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1372' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1371' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1370' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1369' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1368' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1367' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1366' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1365' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1364' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1363' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1362' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1361' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1360' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1359' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1358' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1357' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1356' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1355' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1354' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1353' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1352' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1351' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1350' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1349' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1348' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1347' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1346' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1345' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1344' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1343' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1342' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1341' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1340' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1339' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1338' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1337' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1336' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1335' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1334' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1333' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1332' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1331' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1330' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1329' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1328' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1327' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1326' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1325' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1324' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1323' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1322' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1321' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1320' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1319' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1318' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1317' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1316' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1315' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1314' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1313' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1312' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1311' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1310' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1309' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1308' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1307' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1306' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1305' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1304' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1303' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1302' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1301' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1300' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1299' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1298' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1297' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1296' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1295' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1294' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1293' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1292' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1291' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1290' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1289' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1288' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1287' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1286' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1285' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1284' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1283' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1282' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1281' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1280' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1279' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1278' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1277' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1276' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1275' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1274' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1273' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1272' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1271' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1270' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1269' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1268' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1267' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1266' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1265' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1264' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1263' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1262' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1261' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1260' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1259' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1258' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1257' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1256' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1255' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1254' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1253' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1252' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1251' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1250' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1249' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1248' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1247' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1246' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1245' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1244' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1243' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1242' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1241' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1240' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1239' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1238' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1237' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1236' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1235' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1234' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1233' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1232' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1231' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1230' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1229' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1228' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1227' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1226' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1225' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1224' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1223' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1222' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1221' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1220' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1219' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1218' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1217' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1216' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1215' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1214' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1213' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1212' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1211' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1210' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1209' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1208' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1207' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1206' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1205' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1204' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1203' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1202' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1201' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1200' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1199' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1198' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1197' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1196' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1195' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1194' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1193' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1192' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1191' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1190' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1189' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1188' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1187' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1186' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1185' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1184' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1183' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1182' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1181' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1180' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1179' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1178' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1177' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1176' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1175' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1174' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1173' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1172' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1171' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1170' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1169' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1168' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1167' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1166' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1165' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1164' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1163' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1162' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1161' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1160' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1159' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1158' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1157' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1156' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1155' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1154' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1153' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1152' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1151' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1150' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1149' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1148' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1147' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1146' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1145' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1144' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1143' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1142' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1141' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1140' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1139' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1138' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1137' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1136' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1135' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1134' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1133' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1132' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1131' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1130' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1129' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1128' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1127' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1126' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1125' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1124' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1123' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1122' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1121' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1120' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1119' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1118' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1117' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1116' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1115' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1114' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1113' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1112' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1111' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1110' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1109' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1108' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1107' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1106' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1105' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1104' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1103' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1102' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1101' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1100' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1099' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1098' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1097' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1096' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1095' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1094' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1093' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1092' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1091' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1090' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1089' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1088' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1087' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1086' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1085' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1084' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1083' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1082' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1081' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1080' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1079' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1078' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1077' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1076' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1075' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1074' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1073' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1072' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1071' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1070' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1069' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1068' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1067' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1066' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1065' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1064' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1063' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1062' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1061' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1060' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1059' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1058' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1057' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1056' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1055' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1054' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1053' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1052' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1051' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1050' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1049' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1048' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1047' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1046' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1045' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1044' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1043' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1042' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1041' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1040' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1039' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1038' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1037' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1036' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1035' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1034' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1033' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1032' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1031' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1030' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1029' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1028' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1027' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1026' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1025' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1024' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1023' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1022' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1021' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1020' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1019' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1018' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1017' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1016' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1015' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1014' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1013' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1012' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1011' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1010' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1009' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1008' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1007' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1006' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1005' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1004' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1003' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1002' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1001' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1000' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-999' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-998' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-997' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-996' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-995' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-994' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-993' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-992' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-991' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-990' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-989' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-988' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-987' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-986' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-985' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-984' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-983' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-982' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-981' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-980' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-979' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-978' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-977' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-976' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-975' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-974' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-973' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-972' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-971' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-970' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-969' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-968' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-967' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-966' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-965' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-964' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-963' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-962' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-961' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-960' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-959' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-958' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-957' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-956' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-955' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-954' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-953' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-952' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-951' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-950' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-949' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-948' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-947' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-946' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-945' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-944' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-943' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-942' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-941' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-940' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-939' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-938' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-937' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-936' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-935' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-934' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-933' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-932' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-931' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-930' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-929' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-928' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-927' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-926' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-925' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-924' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-923' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-922' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-921' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-920' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-919' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-918' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-917' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-916' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-915' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-914' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-913' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-912' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-911' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-910' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-909' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-908' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-907' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-906' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-905' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-904' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-903' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-902' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-901' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-900' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-899' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-898' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-897' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-896' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-895' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-894' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-893' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-892' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-891' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-890' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-889' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-888' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-887' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-886' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-885' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-884' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-883' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-882' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-881' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-880' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-879' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-878' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-877' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-876' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-875' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-874' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-873' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-872' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-871' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-870' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-869' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-868' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-867' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-866' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-865' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-864' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-863' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-862' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-861' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-860' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-859' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-858' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-857' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-856' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-855' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-854' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-853' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-852' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-851' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-850' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-849' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-848' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-847' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-846' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-845' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-844' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-843' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-842' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-841' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-840' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-839' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-838' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-837' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-836' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-835' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-834' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-833' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-832' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-831' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-830' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-829' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-828' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-827' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-826' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-825' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-824' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-823' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-822' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-821' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-820' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-819' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-818' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-817' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-816' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-815' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-814' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-813' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-812' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-811' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-810' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-809' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-808' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-807' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-806' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-805' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-804' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-803' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-802' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-801' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-800' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-799' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-798' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-797' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-796' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-795' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-794' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-793' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-792' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-791' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-790' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-789' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-788' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-787' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-786' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-785' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-784' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-783' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-782' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-781' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-780' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-779' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-778' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-777' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-776' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-775' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-774' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-773' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-772' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-771' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-770' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-769' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-768' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-767' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-766' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-765' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-764' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-763' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-762' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-761' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-760' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-759' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-758' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-757' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-756' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-755' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-754' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-753' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-752' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-751' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-750' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-749' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-748' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-747' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-746' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-745' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-744' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-743' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-742' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-741' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-740' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-739' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-738' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-737' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-736' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-735' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-734' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-733' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-732' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-731' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-730' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-729' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-728' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-727' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-726' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-725' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-724' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-723' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-722' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-721' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-720' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-719' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-718' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-717' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-716' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-715' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-714' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-713' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-712' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-711' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-710' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-709' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-708' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-707' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-706' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-705' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-704' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-703' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-702' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-701' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-700' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-699' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-698' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-697' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-696' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-695' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-694' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-693' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-692' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-691' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-690' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-689' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-688' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-687' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-686' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-685' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-684' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-683' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-682' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-681' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-680' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-679' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-678' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-677' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-676' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-675' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-674' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-673' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-672' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-671' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-670' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-669' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-668' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-667' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-666' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-665' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-664' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-663' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-662' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-661' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-660' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-659' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-658' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-657' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-656' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-655' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-654' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-653' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-652' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-651' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-650' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-649' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-648' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-647' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-646' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-645' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-644' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-643' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-642' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-641' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-640' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-639' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-638' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-637' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-636' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-635' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-634' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-633' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-632' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-631' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-630' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-629' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-628' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-627' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-626' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-625' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-624' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-623' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-622' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-621' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-620' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-619' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-618' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-617' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-616' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-615' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-614' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-613' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-612' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-611' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-610' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-609' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-608' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-607' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-606' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-605' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-604' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-603' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-602' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-601' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-600' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-599' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-598' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-597' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-596' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-595' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-594' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-593' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-592' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-591' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-590' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-589' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-588' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-587' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-586' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-585' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-584' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-583' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-582' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-581' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-580' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-579' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-578' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-577' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-576' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-575' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-574' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-573' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-572' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-571' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-570' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-569' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-568' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-567' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-566' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-565' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-564' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-563' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-562' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-561' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-560' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-559' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-558' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-557' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-556' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-555' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-554' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-553' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-552' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-551' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-550' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-549' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-548' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-547' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-546' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-545' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-544' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-543' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-542' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-541' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-540' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-539' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-538' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-537' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-536' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-535' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-534' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-533' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-532' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-531' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-530' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-529' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-528' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-527' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-526' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-525' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-524' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-523' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-522' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-521' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-520' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-519' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-518' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-517' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-516' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-515' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-514' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-513' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-512' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-511' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-510' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-509' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-508' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-507' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-506' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-505' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-504' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-503' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-502' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-501' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-500' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-499' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-498' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-497' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-496' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-495' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-494' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-493' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-492' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-491' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-490' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-489' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-488' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-487' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-486' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-485' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-484' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-483' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-482' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-481' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-480' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-479' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-478' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-477' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-476' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-475' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-474' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-473' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-472' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-471' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-470' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-469' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-468' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-467' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-466' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-465' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-464' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-463' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-462' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-461' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-460' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-459' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-458' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-457' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-456' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-455' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-454' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-453' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-452' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-451' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-450' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-449' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-448' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-447' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-446' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-445' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-444' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-443' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-442' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-441' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-440' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-439' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-438' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-437' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-436' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-435' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-434' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-433' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-432' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-431' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-430' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-429' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-428' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-427' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-426' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-425' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-424' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-423' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-422' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-421' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-420' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-419' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-418' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-417' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-416' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-415' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-414' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-413' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-412' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-411' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-410' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-409' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-408' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-407' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-406' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-405' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-404' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-403' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-402' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-401' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-400' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-399' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-398' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-397' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-396' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-395' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-394' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-393' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-392' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-391' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-390' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-389' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-388' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-387' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-386' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-385' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-384' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-383' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-382' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-381' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-380' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-379' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-378' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-377' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-376' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-375' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-374' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-373' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-372' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-371' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-370' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-369' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-368' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-367' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-366' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-365' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-364' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-363' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-362' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-361' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-360' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-359' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-358' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-357' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-356' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-355' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-354' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-353' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-352' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-351' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-350' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-349' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-348' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-347' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-346' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-345' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-344' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-343' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-342' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-341' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-340' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-339' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-338' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-337' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-336' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-335' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-334' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-333' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-332' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-331' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-330' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-329' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-328' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-327' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-326' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-325' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-324' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-323' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-322' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-321' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-320' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-319' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-318' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-317' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-316' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-315' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-314' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-313' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-312' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-311' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-310' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-309' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-308' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-307' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-306' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-305' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-304' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-303' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-302' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-301' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-300' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-299' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-298' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-297' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-296' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-295' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-294' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-293' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-292' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-291' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-290' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-289' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-288' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-287' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-286' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-285' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-284' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-283' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-282' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-281' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-280' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-279' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-278' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-277' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-276' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-275' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-274' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-273' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-272' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-271' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-270' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-269' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-268' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-267' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-266' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-265' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-264' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-263' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-262' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-261' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-260' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-259' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-258' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-257' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-256' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-255' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-254' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-253' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-252' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-251' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-250' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-249' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-248' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-247' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-246' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-245' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-244' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-243' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-242' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-241' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-240' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-239' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-238' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-237' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-236' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-235' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-234' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-233' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-232' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-231' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-230' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-229' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-228' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-227' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-226' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-225' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-224' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-223' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-222' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-221' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-220' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-219' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-218' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-217' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-216' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-215' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-214' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-213' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-212' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-211' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-210' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-209' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-208' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-207' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-206' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-205' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-204' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-203' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-202' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-201' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-200' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-199' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-198' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-197' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-196' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-195' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-194' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-193' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-192' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-191' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-190' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-189' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-188' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-187' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-186' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-185' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-184' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-183' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-182' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-181' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-180' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-179' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-178' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-177' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-176' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-175' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-174' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-173' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-172' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-171' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-170' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-169' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-168' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-167' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-166' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-165' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-164' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-163' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-162' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-161' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-160' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-159' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-158' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-157' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-156' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-155' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-154' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-153' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-152' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-151' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-150' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-149' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-148' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-147' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-146' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-145' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-144' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-143' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-142' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-141' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-140' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-139' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-138' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-137' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-136' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-135' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-134' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-133' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-132' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-131' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-130' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-129' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-128' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-127' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-126' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-125' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-124' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-123' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-122' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-121' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-120' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-119' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-118' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-117' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-116' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-115' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-114' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-113' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-112' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-111' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-110' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-109' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-108' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-107' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-106' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-105' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-104' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-103' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-102' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-101' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-100' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-99' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-98' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-97' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-96' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-95' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-94' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-93' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-92' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-91' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-90' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-89' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-88' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-87' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-86' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-85' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-84' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-83' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-82' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-81' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-80' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-79' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-78' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-77' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-76' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-75' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-74' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-73' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-72' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-71' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-70' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-69' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-68' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-67' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-66' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-65' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-64' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-63' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-62' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-61' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-60' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-59' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-58' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-57' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-56' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-55' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-54' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-53' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-52' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-51' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-50' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-49' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-48' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-47' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-46' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-45' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-44' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-43' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-42' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-41' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-40' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-39' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-38' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-37' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-36' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-35' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-34' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-33' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-32' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-31' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-30' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-29' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-28' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-27' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-26' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-25' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-24' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-23' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-22' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-21' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-20' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-19' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-18' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-17' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-16' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-15' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-14' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-12' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-11' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-10' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-9' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-8' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-7' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-6' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-5' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-3' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2' coro=<run_inference.<locals>.wrapped_task() done, defined at /data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py:120> exception=NotFoundError(\"Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 121, in wrapped_task\n",
      "    res = await infer_one(client, model, p, sem, max_retries, request_timeout, temperature, top_p, max_tokens, n, presence_penalty)\n",
      "  File \"/data/workspace/yanmy/HybridRAG/H-STAR/utils/async_llm.py\", line 61, in infer_one\n",
      "    resp = await client.chat.completions.create(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/aizoo/miniconda3/envs/hstar/lib/python3.9/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `/data/workspace/yanmy/models/Qwen3-4B-Instruct-2507` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing scores for 2024 items with batch size 16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize:   0%|          | 0/127 [00:00<?, ?it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "pre tokenize: 100%|██████████| 127/127 [00:00<00:00, 316.60it/s]\n",
      "Compute Scores: 100%|██████████| 127/127 [00:03<00:00, 36.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scores in the original dictionary...\n",
      "Reranking complete.\n",
      "Filtering items to rerank (Terminated=False and data_entry exists)...\n",
      "No items to process.\n",
      "Filtering items to rerank (Terminated=False and data_entry exists)...\n",
      "No items to process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "check_tau = check_tau\n",
    "for loop in range(3):\n",
    "    updated_data = batch_rerank_scores(reranker_model, Check_Model_Data_Sequence, batch_size=16)\n",
    "    Check_Model_Data_Sequence = updated_data\n",
    "    ## Check Terminal Status\n",
    "    for key in Check_Model_Data_Sequence.keys():\n",
    "        if Check_Model_Data_Sequence[key]['Terminated'] == True:\n",
    "            continue\n",
    "        else:\n",
    "            if Check_Model_Data_Sequence[key]['Check_Status'] == True:\n",
    "                if Check_Model_Data_Sequence[key]['Check_Score'] >= check_tau: ## 0.5 threshold\n",
    "                    Check_Model_Data_Sequence[key]['Terminated'] = True\n",
    "                else:\n",
    "                    Check_Model_Data_Sequence[key]['Terminated'] = False\n",
    "                    Check_Model_Data_Sequence[key]['Check_Status'] = False\n",
    "                    Check_Model_Data_Sequence[key]['Check_Score'] = 0.0\n",
    "                    current_sequence = Check_Model_Data_Sequence[key]['Sequence']\n",
    "                    ROLLBACK_seq, terminated_flag = ROLLBACK(current_sequence)\n",
    "                    Check_Model_Data_Sequence[key]['Sequence'] = ROLLBACK_seq\n",
    "                    Check_Model_Data_Sequence[key]['Terminated'] = terminated_flag\n",
    "                    if terminated_flag == False:\n",
    "                        data_entry = Prepare_Data_for_Operator_Sequence(key,ROLLBACK_seq,dataset, processed_table)\n",
    "                        Check_Model_Data_Sequence[key]['data_entry'] = data_entry\n",
    "            else:\n",
    "                raise ValueError(\"Check Status should be True when Terminated is False after reranking.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker_model = FlagReranker(check_moedl_path, use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 10\n",
    "SQL_list_final = []\n",
    "for index in range(len(dataset)):\n",
    "    sequence = Check_Model_Data_Sequence[index]['Sequence']\n",
    "    if sequence==[] or sequence.__contains__('Execute_SQL'):\n",
    "        SQL_list_final.append(index)\n",
    "add_sql_list = list(set(SQL_list_final) - set(LLM_query_list['Execute_SQL']['index']))\n",
    "add_sql_query_list = []\n",
    "for index in add_sql_list:\n",
    "    prompt = build_wikitq_prompt_from_df(dataset,wikitq_df_processed[index],index,template_path='../prompts/sql_reason_tabfact.txt',processed=True)\n",
    "    add_sql_query_list.extend([prompt])\n",
    "add_sql_response_list = response_vllm(add_sql_query_list, sample_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## step 11: generate QA result\n",
    "prompt_list = []\n",
    "for index in range(len(dataset)):\n",
    "    sequence = Check_Model_Data_Sequence[index]['Sequence']\n",
    "    prompt = build_wikitq_prompt_from_df(dataset,Check_Model_Data_Sequence[index]['data_entry']['table'],index,template_path='../prompts/text_reason_tabfact.txt',processed=True)\n",
    "    if sequence==[] or sequence.__contains__('Execute_SQL'):\n",
    "    # if sequence.__contains__('Execute_SQL'):\n",
    "        # try:\n",
    "        evidence = table_to_str_sql(processed_table['Execute_SQL'][index])\n",
    "        prompt = prompt + evidence\n",
    "        print(f'SQL at index {index}')\n",
    "    prompt_list.append(prompt)\n",
    "# wikitq_df['instruction'] = prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 2024/2024 [02:33<00:00, 13.21it/s, est. speed input=28679.35 toks/s, output=2426.97 toks/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f303dbd67594983b13ac97f7e237c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Samples: 1883; Total Samples: 2024\n",
      "Accuracy: 93.03\n"
     ]
    }
   ],
   "source": [
    "## step 11: execute QA\n",
    "# qa_final = response_vllm(llm,prompt_list, sample_num=1)\n",
    "qa_final = infer_prompts(prompt_list,temperature=0, top_p=1, sample_num=1,llm_path = '/data/workspace/yanmy/models/Qwen3-30B-A3B-Instruct-2507-FP8')\n",
    "wikitq_df = pd.DataFrame(dataset)\n",
    "wikitq_df['instruction'] = prompt_list\n",
    "wikitq_df['predict'] = qa_final[0]\n",
    "## step 12: evaluate\n",
    "wikitq_df['predict'] = [str(s) for s in qa_final[0]]\n",
    "acc_all, error_index_all, format_error_index_all = evaluate_predictions(dataset_name, wikitq_df, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct Samples: 1750; Total Samples: 2024\n",
    "Accuracy: 86.46（Training-Free Router）\n",
    "Correct Samples: 1765; Total Samples: 2024\n",
    "Accuracy: 87.20 (w/o Check)\n",
    "Correct Samples: 1763; Total Samples: 2024\n",
    "Accuracy: 87.10 (w/o table extraction)\n",
    "Correct Samples: 1775; Total Samples: 2024\n",
    "Accuracy: 87.70 （w/o SQL）\n",
    "Correct Samples: 1773; Total Samples: 2024\n",
    "Accuracy: 87.55 （w/o RAG）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hstar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
